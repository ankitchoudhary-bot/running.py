name: Define Objective Function
description: Writes the objective() function to a .py file for use in the next brick
outputs:
  - name: model
    type: file
implementation:
  container:
    image: python:3.9
    command:
      - sh
      - -c
      - |
        mkdir -p /shared_output && \
        echo "def objective(parameters):" > /shared_output/objective.py && \
        echo "    lr = float(parameters[\"lr\"])" >> /shared_output/objective.py && \
        echo "    threshold = float(parameters[\"threshold\"])" >> /shared_output/objective.py && \
        echo "    import time" >> /shared_output/objective.py && \
        echo "    import torch" >> /shared_output/objective.py && \
        echo "    import torch.nn as nn" >> /shared_output/objective.py && \
        echo "    from torchvision.datasets import MNIST" >> /shared_output/objective.py && \
        echo "    from torchvision.transforms import Compose, ToTensor, Normalize, Lambda" >> /shared_output/objective.py && \
        echo "    from torch.utils.data import DataLoader" >> /shared_output/objective.py && \
        echo "    from torch.optim import Adam" >> /shared_output/objective.py && \
        echo "    from tqdm import tqdm" >> /shared_output/objective.py && \
        echo "    time.sleep(5)" >> /shared_output/objective.py && \
        echo "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")" >> /shared_output/objective.py && \
        echo "    def MNIST_loaders(train_batch_size=5000, test_batch_size=1000):" >> /shared_output/objective.py && \
        echo "        transform = Compose([" >> /shared_output/objective.py && \
        echo "            ToTensor()," >> /shared_output/objective.py && \
        echo "            Normalize((0.1307,), (0.3081,))," >> /shared_output/objective.py && \
        echo "            Lambda(lambda x: torch.flatten(x))])" >> /shared_output/objective.py && \
        echo "        train_loader = DataLoader(MNIST('./data/', train=True, download=True, transform=transform), batch_size=train_batch_size, shuffle=True)" >> /shared_output/objective.py && \
        echo "        test_loader = DataLoader(MNIST('./data/', train=False, download=True, transform=transform), batch_size=test_batch_size, shuffle=False)" >> /shared_output/objective.py && \
        echo "        return train_loader, test_loader" >> /shared_output/objective.py && \
        echo "    def overlay_y_on_x(x, y):" >> /shared_output/objective.py && \
        echo "        x_ = x.clone()" >> /shared_output/objective.py && \
        echo "        x_[:, :10] *= 0.0" >> /shared_output/objective.py && \
        echo "        x_[range(x.shape[0]), y] = x.max()" >> /shared_output/objective.py && \
        echo "        return x_" >> /shared_output/objective.py && \
        echo "    class Layer(nn.Linear):" >> /shared_output/objective.py && \
        echo "        def __init__(self, in_features, out_features, lr, threshold, bias=True, device=None, dtype=None):" >> /shared_output/objective.py && \
        echo "            super().__init__(in_features, out_features, bias, device, dtype)" >> /shared_output/objective.py && \
        echo "            self.relu = torch.nn.ReLU()" >> /shared_output/objective.py && \
        echo "            self.opt = Adam(self.parameters(), lr=lr)" >> /shared_output/objective.py && \
        echo "            self.threshold = threshold" >> /shared_output/objective.py && \
        echo "            self.num_epochs = 2" >> /shared_output/objective.py && \
        echo "        def forward(self, x):" >> /shared_output/objective.py && \
        echo "            x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)" >> /shared_output/objective.py && \
        echo "            return self.relu(torch.mm(x_direction, self.weight.T) + self.bias.unsqueeze(0))" >> /shared_output/objective.py && \
        echo "        def train(self, x_pos, x_neg):" >> /shared_output/objective.py && \
        echo "            for _ in tqdm(range(self.num_epochs)):" >> /shared_output/objective.py && \
        echo "                g_pos = self.forward(x_pos).pow(2).mean(1)" >> /shared_output/objective.py && \
        echo "                g_neg = self.forward(x_neg).pow(2).mean(1)" >> /shared_output/objective.py && \
        echo "                loss = torch.log(1 + torch.exp(torch.cat([-g_pos + self.threshold, g_neg - self.threshold]))).mean()" >> /shared_output/objective.py && \
        echo "                self.opt.zero_grad()" >> /shared_output/objective.py && \
        echo "                loss.backward()" >> /shared_output/objective.py && \
        echo "                self.opt.step()" >> /shared_output/objective.py && \
        echo "            return self.forward(x_pos).detach(), self.forward(x_neg).detach()" >> /shared_output/objective.py && \
        echo "    class Net(torch.nn.Module):" >> /shared_output/objective.py && \
        echo "        def __init__(self, dims, lr, threshold):" >> /shared_output/objective.py && \
        echo "            super().__init__()" >> /shared_output/objective.py && \
        echo "            self.layers = [Layer(dims[i], dims[i+1], lr, threshold).to(device) for i in range(len(dims)-1)]" >> /shared_output/objective.py && \
        echo "        def predict(self, x):" >> /shared_output/objective.py && \
        echo "            goodness_per_label = []" >> /shared_output/objective.py && \
        echo "            for label in range(10):" >> /shared_output/objective.py && \
        echo "                h = overlay_y_on_x(x, label)" >> /shared_output/objective.py && \
        echo "                goodness = []" >> /shared_output/objective.py && \
        echo "                for layer in self.layers:" >> /shared_output/objective.py && \
        echo "                    h = layer(h)" >> /shared_output/objective.py && \
        echo "                    goodness.append(h.pow(2).mean(1))" >> /shared_output/objective.py && \
        echo "                goodness_per_label.append(sum(goodness).unsqueeze(1))" >> /shared_output/objective.py && \
        echo "            return torch.cat(goodness_per_label, 1).argmax(1)" >> /shared_output/objective.py && \
        echo "        def train(self, x_pos, x_neg):" >> /shared_output/objective.py && \
        echo "            h_pos, h_neg = x_pos, x_neg" >> /shared_output/objective.py && \
        echo "            for layer in self.layers:" >> /shared_output/objective.py && \
        echo "                h_pos, h_neg = layer.train(h_pos, h_neg)" >> /shared_output/objective.py && \
        echo "    torch.manual_seed(1234)" >> /shared_output/objective.py && \
        echo "    train_loader, test_loader = MNIST_loaders()" >> /shared_output/objective.py && \
        echo "    net = Net([784, 50, 50], lr, threshold)" >> /shared_output/objective.py && \
        echo "    x, y = next(iter(train_loader))" >> /shared_output/objective.py && \
        echo "    x, y = x.to(device), y.to(device)" >> /shared_output/objective.py && \
        echo "    x_pos = overlay_y_on_x(x, y)" >> /shared_output/objective.py && \
        echo "    rnd = torch.randperm(x.size(0))" >> /shared_output/objective.py && \
        echo "    x_neg = overlay_y_on_x(x, y[rnd])" >> /shared_output/objective.py && \
        echo "    net.train(x_pos, x_neg)" >> /shared_output/objective.py && \
        echo "    x_te, y_te = next(iter(test_loader))" >> /shared_output/objective.py && \
        echo "    x_te, y_te = x_te.to(device), y_te.to(device)" >> /shared_output/objective.py && \
        echo "    acc = net.predict(x_te).eq(y_te).float().mean().item()" >> /shared_output/objective.py && \
        echo "    print(f\"accuracy={acc}\")" >> /shared_output/objective.py && \
        echo "    return acc" >> /shared_output/objective.py
    fileOutputs:
      model: /shared_output/objective.py


